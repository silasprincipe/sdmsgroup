{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is `xarray` and how to use for simple applications\n",
    "\n",
    "Xarray is a Python library that simplifies working with multi-dimensional labeled arrays. It is especially useful for working with netCDF files and other scientific datasets, such as those used in climate and meteorological research. With Xarray, you can easily perform indexing, slicing, aggregations, and group-by operations on multi-dimensional data, making data analysis, visualization, and processing more intuitive and efficient.\n",
    "\n",
    "You can also uxe `xarray` directly from R. Instead of using `import` do this:\n",
    "\n",
    "``` r\n",
    "library(reticulate)\n",
    "xr <- import(\"xarray\")\n",
    "```\n",
    "\n",
    "Then, you can call the functions as:\n",
    "\n",
    "``` r\n",
    "ds <- xr$open_dataset(\"dataset path...\")\n",
    "```\n",
    "\n",
    "And methods with:\n",
    "\n",
    "``` r\n",
    "ds$to_netcdf()\n",
    "```\n",
    "\n",
    "That is, just change the `.` (dot) by `$` (dollar)\n",
    "\n",
    "I will show two examples. The first, using a `netCDF` file. The other, accessing directly the ERDDAP server. You can also open `zarr`, `tif` and other formats. For a very nice example, check this notebook: https://github.com/pangeo-gallery/osm2020tutorial/blob/master/AWS-notebooks/aws_mur_sst_tutorial_long.ipynb\n",
    "\n",
    "## From a `netCDF` file\n",
    "\n",
    "First we download a small sample of data from the CoralTemp product (from NOAA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is all ChatGPT:\n",
    "import xarray as xr\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Base URL components\n",
    "base_url = \"https://www.star.nesdis.noaa.gov/pub/socd/mecb/crw/data/5km/v3.1_op/nc/v1.0/daily/sst/2020/\"\n",
    "file_prefix = \"coraltemp_v3.1_\"\n",
    "file_suffix = \".nc\"\n",
    "\n",
    "# Directory to save downloaded files\n",
    "output_dir = \"internal/sst\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Date range for January 2020\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2020, 1, 5)\n",
    "\n",
    "# Loop through each day in January 2020\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    # Format the date as YYYYMMDD\n",
    "    date_str = current_date.strftime(\"%Y%m%d\")\n",
    "    # Construct the full URL for the current date's file\n",
    "    file_url = f\"{base_url}{file_prefix}{date_str}{file_suffix}\"\n",
    "    # Path to save the downloaded file\n",
    "    output_path = os.path.join(output_dir, f\"{file_prefix}{date_str}{file_suffix}\")\n",
    "    \n",
    "    # Download the file\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {file_url}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {file_url} (Status code: {response.status_code})\")\n",
    "    \n",
    "    # Move to the next day\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Directory containing the downloaded NetCDF files\n",
    "input_dir = output_dir\n",
    "\n",
    "# List all NetCDF files in the directory\n",
    "nc_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.nc')]\n",
    "\n",
    "# Open multiple NetCDF files and concatenate them along the time dimension\n",
    "combined_ds = xr.open_mfdataset(nc_files, combine='by_coords')\n",
    "\n",
    "# Save the combined dataset to a new NetCDF file\n",
    "output_file = \"combined_january_2020.nc\"\n",
    "combined_ds.to_netcdf(output_file)\n",
    "\n",
    "print(f\"Combined NetCDF file saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be an example of how to open a dataset with multiple layers - in that case, only time. But you can have datasets with multiple dimensions! For example depth, different variables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "sst = xr.open_dataset(\"combined_january_2020.nc\")\n",
    "\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this nice overview you can see that there are three coordinates (lat, lon and time) and three variables, being one the analysed_sst. Let's extract the analysed_sst and get a mean of that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_analysed = sst[\"analysed_sst\"]\n",
    "\n",
    "sst_analysed\n",
    "\n",
    "sst_mean = sst_analysed.mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is nice, but you can also directly access S3 files and ERDDAP servers. Let's access monthly SST data from this same product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coraltemp = xr.open_dataset(\"https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\")\n",
    "\n",
    "coraltemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that time is a much bigger set - 481 values. We will subset both the sea_surface_temperature variable and the time coordinate for a smaller period (6 months). Then we will get the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_subset = coraltemp[\"sea_surface_temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also slice the area, to make faster to process\n",
    "ct_sub_date = ct_subset.sel(time = slice(\"2020-01-01\", \"2020-06-01\"),\n",
    "                            latitude = slice(40, 0),\n",
    "                            longitude = slice(-20, 20))\n",
    "ct_sub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part takes some time, because now the data is being downloaded and processed\n",
    "\n",
    "ct_mean = ct_sub_date.mean('time', keep_attrs=True,skipna=False)\n",
    "\n",
    "ct_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_mean.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
